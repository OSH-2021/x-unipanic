# 单机性能测试及优化

## 测试读写速度

### 创建存储池

`ceph osd pool create test 64 64`

### 测试写速度

**必须先写再读，所以先测写速度。**

```bash
[root@centos-vm my-cluster]# rados bench -p test 10 write --no-cleanup
hints = 1
Maintaining 16 concurrent writes of 4194304 bytes to objects of size 4194304 for up to 10 seconds or 0 objects
Object prefix: benchmark_data_centos-vm.localdomain_1967
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
    0       0         0         0         0         0           -           0
    1      16        83        67   267.278       268    0.131075    0.223447
    2      16       113        97   193.686       120    0.238125    0.268185
    3      16       161       145   192.862       192     0.14377    0.267906
    4      16       170       154   153.702        36     1.18652    0.316115
    5      16       170       154   123.004         0           -    0.316115
    6      16       179       163   108.519        18     2.47607    0.475307
    7      16       198       182   103.875        76   0.0626805    0.558973
    8      16       210       194   96.8698        48     1.55849    0.621235
    9      16       219       203   90.1113        36    0.429731    0.642184
   10      16       219       203   81.1064         0           -    0.642184
Total time run:         10.5615
Total writes made:      220
Write size:             4194304
Object size:            4194304
Bandwidth (MB/sec):     83.3216
Stddev Bandwidth:       88.8447
Max bandwidth (MB/sec): 268
Min bandwidth (MB/sec): 0
Average IOPS:           20
Stddev IOPS:            22.2501
Max IOPS:               67
Min IOPS:               0
Average Latency(s):     0.763736
Stddev Latency(s):      0.914939
Max latency(s):         3.45019
Min latency(s):         0.00711988
```

### 测试读速度

```bash
[root@centos-vm my-cluster]# rados bench -p test 10 seq
hints = 1
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
    0      16        23         7   271.433        -1   0.0989453   0.0716597
    1      16       150       134    484.47       508    0.122942    0.124119
Total time run:       1.72704
Total reads made:     220
Read size:            4194304
Object size:          4194304
Bandwidth (MB/sec):   509.543
Average IOPS:         127
Stddev IOPS:          0
Max IOPS:             127
Min IOPS:             127
Average Latency(s):   0.124248
Max latency(s):       0.203695
Min latency(s):       0.0540381
```

## 性能优化

参照：

[Ceph 架构及性能优化 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/352544834)

[Configuration — Ceph Documentation](https://docs.ceph.com/en/latest/rados/configuration/)

**硬件无法修改，只从软件层面修改。**

### 对虚拟机进行修改

1. 修改 kernel pid max

```bash
echo 4194303 > /proc/sys/kernel/pid_max
```

2. 修改挂载的硬盘的I/O scheduler

SSD用noop，SATA/SAS用deadline

```bash
echo "noop" >/sys/block/sd[x]/queue/scheduler
```

其中sd[x]为挂载的硬盘，用于OSD的数据和日志存储。

`/sys/block/sd[x]/queue/scheduler`原本的内容为：

```bash
noop [deadline] cfq
```

即选中deadline。

三种模式的区别：

* noop：简单地将所有的I/O请求放入FIFO（先进先出）队列
* deadline：一个I/O请求到达ddl时，获得最高优先级
* cfq：绝对公平队列，轮询

### 修改配置参数

**我们主要是针对写操作优化了参数，因此结果也主要是写操作的性能得到了优化。**

在`~/my-cluster/ceph.conf`中输入以下内容：

```bash
[global]
auth_cluster_required = none
auth_service_required = none
auth_client_required = none
#将原本的cephx改为none，省掉了认证的时间


[osd]
osd journal size = 200	#减小日志的大小
osd mkfs type = xfs		#选择合适的文件系统
osd mkfs options xfs = -f -i size=2048

filestore xattr use omap = true
filestore min sync interval = 10
filestore max sync interval = 15
filestore queue max ops = 25000
filestore queue max bytes = 1048576000
filestore queue committing max ops = 50000
filestore queue committing max bytes = 10485760000
filestore split multiple = 8
filestore merge threshold = 40
filestore fd cache size = 32768

journal max write bytes = 1073714824
journal max write entries = 10000
journal queue max ops = 50000
journal queue max bytes = 10485760000

osd max write size = 512
osd client message size cap = 2147483648

osd_scrub_begin_hour = 2
osd_scrub_end_hour = 6
osd_scrub_sleep = 2
osd_scrub_load_threshold = 5
osd_scrub_chunk_min = 5
osd_scrub_chunk_max = 25

osd deep scrub stride = 131072
osd op threads = 16
osd disk threads = 4
osd map cache size = 1024
osd map cache bl size = 128
osd mount options xfs = "rw,noexec,nodev,noatime,nodiratime,nobarrier"
osd recovery op priority = 2
osd recovery max active = 10
osd max backfills = 4
objecter inflight ops = 819200
osd crush chooseleaf type = 0
```

让写入的内容生效：

```bash
ceph-deploy --overwrite-conf config push [hostname]
systemctl restart ceph-mon.target
systemctl restart ceph-osd.target
systemctl restart ceph-mds.target
```

### 优化前测试

#### 写速度

```bash
[root@centos-vm my-cluster]# rados bench -p test 10 write --no-cleanup
hints = 1
Maintaining 16 concurrent writes of 4194304 bytes to objects of size 4194304 for up to 10 seconds or 0 objects
Object prefix: benchmark_data_centos-vm.localdomain_1967
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
    0       0         0         0         0         0           -           0
    1      16        83        67   267.278       268    0.131075    0.223447
    2      16       113        97   193.686       120    0.238125    0.268185
    3      16       161       145   192.862       192     0.14377    0.267906
    4      16       170       154   153.702        36     1.18652    0.316115
    5      16       170       154   123.004         0           -    0.316115
    6      16       179       163   108.519        18     2.47607    0.475307
    7      16       198       182   103.875        76   0.0626805    0.558973
    8      16       210       194   96.8698        48     1.55849    0.621235
    9      16       219       203   90.1113        36    0.429731    0.642184
   10      16       219       203   81.1064         0           -    0.642184
Total time run:         10.5615
Total writes made:      220
Write size:             4194304
Object size:            4194304
Bandwidth (MB/sec):     83.3216
Stddev Bandwidth:       88.8447
Max bandwidth (MB/sec): 268
Min bandwidth (MB/sec): 0
Average IOPS:           20
Stddev IOPS:            22.2501
Max IOPS:               67
Min IOPS:               0
Average Latency(s):     0.763736
Stddev Latency(s):      0.914939
Max latency(s):         3.45019
Min latency(s):         0.00711988
```

#### 顺序读

```bash
[root@centos-vm my-cluster]# rados bench -p test 10 seq
hints = 1
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
    0      16        23         7   271.433        -1   0.0989453   0.0716597
    1      16       150       134    484.47       508    0.122942    0.124119
Total time run:       1.72704
Total reads made:     220
Read size:            4194304
Object size:          4194304
Bandwidth (MB/sec):   509.543
Average IOPS:         127
Stddev IOPS:          0
Max IOPS:             127
Min IOPS:             127
Average Latency(s):   0.124248
Max latency(s):       0.203695
Min latency(s):       0.0540381
```

#### 随机读

```bash
[root@centos-vm elsa]# rados bench -p test 10 rand
hints = 1
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
    0      16        24         8   311.618        -1     0.10211   0.0640892
    1      16       169       153   553.397       580    0.102812    0.109963
    2      16       317       301   571.255       592    0.111701    0.108547
    3      16       460       444   571.052       572    0.116933    0.109727
    4      16       612       596   579.884       608   0.0972692    0.108726
    5      16       753       737   576.556       564    0.146306    0.109408
    6      16       891       875   572.244       552    0.132365    0.110204
    7      16      1028      1012   568.488       548    0.119487    0.111157
    8      16      1174      1158   570.193       584     0.12054    0.110996
    9      16      1313      1297   568.483       556    0.114216    0.111408
Total time run:       10.0597
Total reads made:     1438
Read size:            4194304
Object size:          4194304
Bandwidth (MB/sec):   571.789
Average IOPS:         142
Stddev IOPS:          4.99444
Max IOPS:             152
Min IOPS:             137
Average Latency(s):   0.111389
Max latency(s):       0.182048
Min latency(s):       0.0469862
```

### 优化后测试

#### 写速度

```bash
[root@centos-vm my-cluster]# rados bench -p test 10 write --no-cleanup
hints = 1
Maintaining 16 concurrent writes of 4194304 bytes to objects of size 4194304 for up to 10 seconds or 0 objects
Object prefix: benchmark_data_centos-vm.localdomain_4754
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
    0      16        19         3   212.641        -1   0.0387565   0.0319104
    1      16       101        85   321.736       328    0.194259    0.180713
    2      16       159       143   278.059       232    0.176537    0.176043
    3      16       165       149   157.833        24    0.744717    0.198942
    4      16       189       173   144.867        96    0.154711    0.355902
    5      16       189       173   119.779         0           -    0.355902
    6      16       189       173   102.101         0           -    0.355902
    7      16       239       223   114.682   66.6667    0.182949    0.539351
    8      16       239       223   101.614         0           -    0.539351
    9      16       239       223   91.2194         0           -    0.539351
   10      16       239       223    82.719         0           -    0.539351
Total time run:         10.8015
Total writes made:      240
Write size:             4194304
Object size:            4194304
Bandwidth (MB/sec):     88.8762
Stddev Bandwidth:       115.419
Max bandwidth (MB/sec): 328
Min bandwidth (MB/sec): 0
Average IOPS:           22
Stddev IOPS:            28.8606
Max IOPS:               82
Min IOPS:               0
Average Latency(s):     0.719813
Stddev Latency(s):      1.10778
Max latency(s):         3.35876
Min latency(s):         0.00548276
```

#### 顺序读

```bash
[root@centos-vm my-cluster]# rados bench -p test 10 seq
hints = 1
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
    0      16        23         7   308.297        -1   0.0902509   0.0891863
    1      16       146       130   476.118       492    0.125741    0.126441
Total time run:       1.91666
Total reads made:     240
Read size:            4194304
Object size:          4194304
Bandwidth (MB/sec):   500.87
Average IOPS:         125
Stddev IOPS:          0
Max IOPS:             123
Min IOPS:             123
Average Latency(s):   0.126632
Max latency(s):       0.187835
Min latency(s):       0.0572118
```

#### 随机读

```bash
[root@centos-vm my-cluster]# rados bench -p test 10 rand
hints = 1
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
    0      16        23         7   314.344        -1   0.0885364   0.0874701
    1      16       155       139   508.664       528    0.117733    0.119049
    2      16       290       274   522.906       540    0.118051    0.118438
    3      16       421       405   522.852       524    0.135836    0.119334
    4      16       554       538   525.009       532    0.105089    0.119942
    5      15       681       666   522.425       512    0.131204    0.118837
    6      16       801       785   514.583       476    0.110228     0.12287
    7      16       935       919   517.424       536    0.117486    0.122271
    8      16      1075      1059   522.553       560    0.101047    0.121273
    9      16      1208      1192   523.403       532    0.129255    0.121008
Total time run:       10.0613
Total reads made:     1333
Read size:            4194304
Object size:          4194304
Bandwidth (MB/sec):   529.949
Average IOPS:         132
Stddev IOPS:          5.74456
Max IOPS:             140
Min IOPS:             119
Average Latency(s):   0.120083
Max latency(s):       0.339467
Min latency(s):       0.0564636
```

